{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nose.tools import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Write your imports here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear and Logistic Regression Lab\n",
    "## Getting acquainted with the tools. Performing some common tasks and creating our first models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will receive labs in this format. Edit the file to make everything work.\n",
    "\n",
    "You can add some cells as you wish. Some cells are read-only - you won't be able to edit them.\n",
    "\n",
    "**Notes:** \n",
    "1. **DO NOT** copy everything in a new file. Edit this one (.ipynb), save it and submit it. **DO NOT** rename the file.\n",
    "2. Be careful what is asked of you - all problems have checks that you need to pass in order to get the points.\n",
    "3. There are tests that you can see, as well as hidden tests. You'll have to perform well on both the visible and the hidden tests. **In this assignment only**, there are no hidden tests. This is just for your convenience.\n",
    "4. If you have used other files, upload them too. You don't need to upload any files supplied with the lab assignment.\n",
    "5. Each lab is scored on a scale from 0 to 10. You can get partial credit (e. g. 5 / 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. Read the data (1 point)\n",
    "The dataset comes from [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00222/). It contains information about the marketing of a Portuguese bank.\n",
    "\n",
    "The data you need to read is the `bank.csv` file in the `data` folder (use \";\" as the column separator). The `bank-names.txt` file contains information about the dataset. Read it and you'll get some information about what it contains.\n",
    "\n",
    "Read the dataset using `pandas` (you can use the library with the alias `pd`). Save it in the `bank_data` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6f01f6b16d4cc0c6d70623ffabbb26a3",
     "grade": false,
     "grade_id": "cell-1d1926bb7ca098b5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_data = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a94c4cdc6cdcb12b28ea2e3bbd52489d",
     "grade": true,
     "grade_id": "cell-f5eca6423dc08236",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "assert_is_not_none(bank_data)\n",
    "assert_equal(bank_data.shape, (4521, 17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Separate features and labels (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the explanatory variables and the output variable (it's called `y` in this case). Create two new variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ca3bea52dd3a9545de67ec525ab76ab",
     "grade": false,
     "grade_id": "cell-37165798a822868a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_features = None # explanatory features - 16 total\n",
    "bank_output = None # output feature\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55f252f336e71ee415afaf1e5c70dada",
     "grade": true,
     "grade_id": "cell-bcdd5d7fa2460962",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(bank_features.shape, (4521, 16))\n",
    "assert_equal(bank_output.shape, (4521,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.  Convert categorical variables (1 + 1 points)\n",
    "Convert all categorical variables in `bank_features` into indicator variables (dummies). Save the result in the same variable. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eea54c44bc2385c397b31f95b4236228",
     "grade": false,
     "grade_id": "cell-e08709f9c53b50e0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "78d4866a669be1693501dec677182162",
     "grade": true,
     "grade_id": "cell-526e429563d680df",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(bank_features.shape, (4521, 51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `bank_output` variable to an indicator variable. This can be done in many ways. Look up how in StackOverflow if you get stuck.\n",
    "\n",
    "The goal is to **rewrite the column** (replace the values): it should be numeric, and be equal to 1 if the original value was \"yes\" and 0 otherwise. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d22b12e35316410cff3d988a7ba30358",
     "grade": false,
     "grade_id": "cell-78040e5a440b5171",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ad86b5c5be9567ceca42d0d6c1ccf558",
     "grade": true,
     "grade_id": "cell-280b855388c11990",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(bank_output.dtype, np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4. Perform logistic regression on the original features (1 point)\n",
    "Perform logistic regression. Save the model in the variable `bank_model`. \n",
    "\n",
    "Use all the data. This is not generally recommended but we'll think of a workaround next time.\n",
    "\n",
    "Pass a large number for the parameter `C = 1e6` (which is equivalent to `C = 1000000`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4c2a3af88dc6e6dec25f82993e9d04c0",
     "grade": false,
     "grade_id": "cell-46045c65058e5e8b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_model = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b342c65cc5749cea353896d940905921",
     "grade": true,
     "grade_id": "cell-17cefb4e8081fcdb",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_model)\n",
    "assert_equal(bank_model.C, 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5. Get an estimate of the model performance (1 point)\n",
    "Use `bank_model.score()` to get an accuracy score. We'll talk about what it represents later in the course. Save the resulting score in the variable `accuracy_score`. To generate the score, use all data. Once again, this is not what we do usually but it's a good start anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d1c437ca23c62db5c52ef7dd52827f0d",
     "grade": false,
     "grade_id": "cell-c1ccd2f4394c67ee",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "085747c4b69ea6ed639a36f7bba7d491",
     "grade": true,
     "grade_id": "cell-52c9269442900910",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_almost_equal(accuracy_score, 0.9042247290422473, delta = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to make a note here. If we explore how the output classes are distributed, we can see that \"class 1\" is about 11.5% of all samples, i.e. very few clients actually subscribed after the call, which is expected. This means the data is **highly imbalanced**. In this case, accuracy is not a good measure of the overall model performance. We have to look at other scoring measures to get a better estimate of what's going on.\n",
    "\n",
    "But once again, we're just getting started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's nothing to do here, just execute the cell and view the plot and print results.\n",
    "# Cells like these are here only for your convenience and to help you understand the task better\n",
    "plt.bar([0, 1], [len(bank_output[bank_output == 0]), len(bank_output[bank_output == 1])])\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Positive cases: {:.3f}% of all\".format(bank_output.sum() / len(bank_output) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6. More features  (1 point)\n",
    "The score is pretty high. But can we improve it? One way to try and improve it is to use polynomial features. As we saw, this creates all possible multiples of input features. In the real world, this corresponds to **feature interaction**.\n",
    "\n",
    "Create a model for quadratic features (`degree = 2`). Save it in the variable `quad_feature_transformer`. Also, set `interaction_only` to True: let's suppose we don't want to square each feature. This means that we have all single features $x_1, x_2, \\dots$ and all interactions $x_1x_2, x_1x_3, \\dots$ but no $x_1^2, x_2^2, \\dots$\n",
    "\n",
    "Using it, transform all `bank_features`. Save them in the variable `bank_features_quad`.\n",
    "\n",
    "Note how the number of features exploded: from 51 we get more than 1300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1d9e945981589431cb60fb23f3e292a4",
     "grade": false,
     "grade_id": "cell-f4b5c98c2c3d7ef3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "quad_feature_transformer = None\n",
    "bank_features_quad = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7dc305e61d9755d1fbd8fcab1157e6cd",
     "grade": true,
     "grade_id": "cell-b42599d51988eda2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(quad_feature_transformer.degree, 2)\n",
    "assert_equal(quad_feature_transformer.interaction_only, True)\n",
    "assert_equal(bank_features_quad.shape, (4521, 1327))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7. Train a model on the quadratic features (1 point)\n",
    "You know the drill. Fit a logistic regression model with all data in `bank_features_quad` and `bank_output`. Use `C = 1e6`. Save it in `bank_model_quad`. Score it and save the score in the variable `accuracy_score_quad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "352a0967d85055d7231829c734ee88af",
     "grade": false,
     "grade_id": "cell-13ea36255860f15b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_model_quad = None\n",
    "accuracy_score_quad = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score_quad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "594aac3717cc4b03cc0a8404d533f41a",
     "grade": true,
     "grade_id": "cell-4718eb80c10d4a16",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_model_quad)\n",
    "assert_equal(bank_model_quad.C, 1e6)\n",
    "assert_equal(len(bank_model_quad.coef_[0]), bank_features_quad.shape[1]) # This is a simple check that the model has been trained\n",
    "assert_almost_equal(accuracy_score_quad, 0.9, delta = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting... we have many more features but the accuracy actually dropped a little. We would observe the same behaviour if we took polynomials of degree 3: more than 20 000 features and accuracy less than 0.87.\n",
    "\n",
    "This is our first example of model selection. Why is the seemingly more complex model less accurate? There are two main reasons:\n",
    "* As we said, the default score (accuracy) is not good for this dataset, so its values aren't too relevant.\n",
    "* The number of features is alarmingly high. This leads to what we call \"overfitting\": our model is too complex. We can't quite catch it with this scoring scheme but we will be able to do that later.\n",
    "\n",
    "We can try a lot of things: test our model better, improve our scoring schemes, come up with better features, etc. In general, we need to take care of several things:\n",
    "* Are all parameters relevant? Can we discard some of them and how?\n",
    "* How do we deal with imbalanced data?\n",
    "* Is logistic regression the best type of model overall? Are there models that do better on this data?\n",
    "* What are the best hyperparameters for the model? We chose `C = 1e6` arbitrarily.\n",
    "\n",
    "We'll continue to do this next time. Let's try just one more thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8. Perform normalization and compare results (1 point)\n",
    "We saw very strange results. A part of the problem might be that our data isn't normalized.\n",
    "\n",
    "Use the `MinMaxScaler` to scale all values in `bank_features_quad`. Save them in `bank_features_quad_scaled`. This will take several seconds.\n",
    "\n",
    "Perform a logistic regression on the new, scaled features: `bank_features_quad_scaled` and `bank_output`. Use the same parameters to score it.\n",
    "\n",
    "You should observe that the score improved the score significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "703dd691c73f0b5a7202380746383250",
     "grade": false,
     "grade_id": "cell-972ff9771d00156b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bank_model_quad_scaled = None\n",
    "accuracy_score_quad_scaled = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c4a67017b44aae5b45942d3a2b0c675b",
     "grade": true,
     "grade_id": "cell-617300ee8ad8e106",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_not_none(bank_model_quad)\n",
    "assert_equal(bank_model_quad.C, 1e6)\n",
    "assert_equal(len(bank_model_quad.coef_[0]), bank_features_quad.shape[1])\n",
    "assert_almost_equal(accuracy_score_quad_scaled, 0.969033399690334, delta = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if you do the test, scaling the original features (instead of the quadratic ones) doesn't improve the score much. This is partly because it isn't the best score. Also, our results are a great reminder that **if we have many uncorrelated features, it's almost always a good idea to rescale them**. You can read some papers online, or use the forums to ask if you're interested why exactly this happens.\n",
    "\n",
    "**The main takeaway from this lab** is working with `scikit-learn` is easy but in order to get meaningful results, you need to understand what you're doing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

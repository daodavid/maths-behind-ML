{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9dbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, Markdown , Math \n",
    "\n",
    "sns.set()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed59e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string): display(Markdown(string))\n",
    "def latex(out): printmd(f'{out}')  \n",
    "def pr(string): printmd('***{}***'.format(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe7c37",
   "metadata": {},
   "source": [
    "<h1>Naive Bayes Classifier</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4439046b",
   "metadata": {},
   "source": [
    "<h2>\n",
    "  <p>\n",
    "    <a href =   \"https://github.com/daodavid\" > \n",
    "         author: daodeiv (David Stankov) \n",
    "       <img src=\"https://cdn.thenewstack.io/media/2014/12/github-octocat.png\" align=\"left\" width=\"120\"  alt=\"daodavid\" ></a>\n",
    "    </p>      \n",
    "</h2>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83237613",
   "metadata": {},
   "source": [
    "<h2 id=''> Bayes Theorem </h2>\n",
    "<h6>\n",
    "  <font size=\"4\" face = \"Times New Roma\" color='#3f134f' > \n",
    "    <ul style=\"margin-left: 30px\">\n",
    "      <li><a href='#bayes_theorem'>Bayes Theorem</a> </li> <br>\n",
    "      <!--<li><a href='#int-1'>Introduction </a> </li><br> -->\n",
    "      <li><a href='#deff_softmax'>Softmaxt definition and  how it works?</a> </li><br>\n",
    "      <li><a href='#optimization'>Optimizaton of  Softmax Loss with Gradient Descent (Deep math calculation)</a> </li><br>  \n",
    "      <li><a href='#impl'>Implementation of Softmax using numpy </a> </li><br>\n",
    "       <li><a href='#reg'>Regularization of softmax by learning rate and max iterations</a> </li><br> \n",
    "       <li><a href='#conclusion'>Conclusion</a> </li><br>  \n",
    "        \n",
    "</ul>    \n",
    " </font>\n",
    "  </h6>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69107912",
   "metadata": {},
   "source": [
    "Naive Bayes is one of the simplest supervised ML algorithms meanwhile very efficient and also is able to learn fast and make a quick prediction, therefore it is so useful and popular.\n",
    "Naive Bayes contains two words Naive and Bayes, Bayes because it is built on Bayes Theorem, and Naive because it assumes that features are independent even if they actually are interdependent.It is simple but very powerful and works well with large datasets and sparse matrices. It works really well on text classification problems, and spam filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dec883",
   "metadata": {},
   "source": [
    "<h2 id='bayes_theorem'> Bayes Theorem </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c6b7d",
   "metadata": {},
   "source": [
    "Bayes theorem describes a probability of an event, based on prior knowledge of conditions that might be related to an event.\n",
    "First, let's take the formula of conditional probability and try to derive Bayes Theorem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd78adc",
   "metadata": {},
   "source": [
    "$$p(A|B) = p(B\\cap A)/p(B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c027c6",
   "metadata": {},
   "source": [
    "Probability of event A given B, meaning what is the probability of A when event B is already taken place, which is equal to the probability of A intersection B (the probability of both A and B events are taking place) divided by the probability of B. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24df6f",
   "metadata": {},
   "source": [
    "we have the same for probability of event B given event A $$p(B|A) = p(A\\cap B)/p(A)$$\n",
    "the  $p(A\\cap B)$ and  $p(B\\cap A)$ are basicaly the same. Since they are the same, we can get two formulas and move denominator to the left of the equation,and equate them \n",
    "$$ p(B|A)p(A) = p(A\\cap B) = p(B \\cap A) = p(A|B)p(B) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9b34e",
   "metadata": {},
   "source": [
    "So, when we want to find probability of A given B we can write our equation on this way: <br> <br>\n",
    "$$P(A|B) = P(B|A) * P(A) / P(B)$$,<br> <br> and this is the equation of Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabdc18",
   "metadata": {},
   "source": [
    "* P(A|B) is the posterior probability of class (target) given predictor (attribute).\n",
    "* P(B) is the prior probability of class.\n",
    "* P(B|A) is the likelihood which is the probability of predictor given class.\n",
    "* P(A) is the prior probability of predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f12fa",
   "metadata": {},
   "source": [
    "<h2 id='works'>  How does Binomial Naive Bayes work? </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497823e",
   "metadata": {},
   "source": [
    "For our purposes we going to use <a href='https://www.kaggle.com/datasets/priy998/golf-play-dataset'>Golf Play Dataset<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98b878b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overcast</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>overcast</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>overcast</td>\n",
       "      <td>hot</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook Temperature Humidity  Windy Play\n",
       "0      sunny         hot     high  False   no\n",
       "1      sunny         hot     high   True   no\n",
       "2   overcast         hot     high  False  yes\n",
       "3      rainy        mild     high  False  yes\n",
       "4      rainy        cool   normal  False  yes\n",
       "5      rainy        cool   normal   True   no\n",
       "6   overcast        cool   normal   True  yes\n",
       "7      sunny        mild     high  False   no\n",
       "8      sunny        cool   normal  False  yes\n",
       "9      rainy        mild   normal  False  yes\n",
       "10     sunny        mild   normal   True  yes\n",
       "11  overcast        mild     high   True  yes\n",
       "12  overcast         hot   normal  False  yes\n",
       "13     rainy        mild     high   True   no"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(\"../../../resources/data/golf_df.csv\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c13b4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10b3afe1",
   "metadata": {},
   "source": [
    "We classify whether the day is suitable for playing golf, given the features of the day. The columns represent these features and the rows represent individual entries. If we take the first row of the dataset, we can observe that is not suitable for playing golf if the outlook is rainy, temperature is hot, humidity is high and it is not windy. We make two assumptions here, one as stated above we consider that these predictors are independent. That is, if the temperature is hot, it does not necessarily mean that the humidity is high. Another assumption made here is that all the predictors have an equal effect on the outcome. That is, the day being windy does not have more importance in deciding to play golf or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e7cf9",
   "metadata": {},
   "source": [
    "According to this example, Bayes theorem can be rewritten as: <br> <br>\n",
    "$$P(y|X) = P(X|y) * P(y) / P(X)$$ <br> <br>\n",
    "The variable y is the class variable(play golf), which represents if it is suitable to play golf or not given the conditions. Variable X represent the parameters/features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde61c5b",
   "metadata": {},
   "source": [
    "X is given as , <br>\n",
    " $$X = (x_1,x_2,...,x_n)$$ <br> <br>\n",
    " Here x_1,x_2â€¦.x_n represent the features, i.e they can be mapped to outlook, temperature, humidity and windy. By substituting for X and expanding using the chain rule we get,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effafd5c",
   "metadata": {},
   "source": [
    "because we assume that features x_i are independent we can write for all feature bayes formula as following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71573b03",
   "metadata": {},
   "source": [
    "$$P(y| x_1,x_2,...,x_n ) = \\frac{P(x_1|y).P(x_2|y)...P(x_n|y)P(y)}{P(x_1)P(x_2)...P(x_n)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9777d0d",
   "metadata": {},
   "source": [
    "When the predictors take up a continuous value and are not discrete, we assume that these values are sampled from a gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd44fd",
   "metadata": {},
   "source": [
    "$$P(x_i|y) = \\frac{1}{(2\\pi\\sigma^2_y)^(1/2)}exp\\big(- \\frac { (x_i - \\mu_y)^2}{2\\sigma^2_y}\\big) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d46f0",
   "metadata": {},
   "source": [
    "In our data set the variable are descrete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c296781",
   "metadata": {},
   "source": [
    "Now, you can obtain the values for each by looking at the dataset and substitute them into the equation. For all entries in the dataset, the denominator does not change, it remain static. Therefore, the denominator can be removed and a proportionality can be introduced.\n",
    "$$P(y| x_1,x_2,...,x_n ) \\propto p(y)\\prod_{i=0}^{n}P(x_i|y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1df0c",
   "metadata": {},
   "source": [
    "$P(y=\"yes\"|\\;x_1=\"overcast\") \\propto P(x_1=\"overcast\"|\\;y=\"yes\" )P(y=\"yes\")$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19f9dd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = iris\n",
    "df.groupby(\"Outlook\")[\"Play\"].count().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e506a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Play\"\n",
    "yes = df[df[label] == \"yes\"].groupby(\"Outlook\")[label].count()\n",
    "no = df[df[label] == \"no\"].groupby(\"Outlook\")[label].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed195802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outlook\n",
       "overcast    4\n",
       "rainy       3\n",
       "sunny       2\n",
       "Name: Play, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a37c33c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outlook\n",
       "overcast    0.444444\n",
       "rainy       0.333333\n",
       "sunny       0.222222\n",
       "Name: Play, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = yes/yes.sum()\n",
    "yes\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c62af7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.index = [(lambda i: f'P(x= \"{i}\"|y=\"yes\") =')(i) for i in k.index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5eb13278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(x= \"overcast\"|y=\"yes\") =    0.444444\n",
       "P(x= \"rainy\"|y=\"yes\") =       0.333333\n",
       "P(x= \"sunny\"|y=\"yes\") =       0.222222\n",
       "Name: Play, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f26e122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P(x= \"rainy\"|y=\"yes\") =    0.4\n",
       "P(x= \"sunny\"|y=\"yes\") =    0.6\n",
       "Name: Play, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no = df[df[label] == \"no\"].groupby(\"Outlook\")[label].count()\n",
    "k = no/no.sum()\n",
    "k.index = [(lambda i: f'P(x= \"{i}\"|y=\"yes\") =')(i) for i in k.index] \n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb3a73",
   "metadata": {},
   "source": [
    "if we get P(x= \"sunny\"|y=\"No\") =    0.6 <br>\n",
    "and P(x= \"sunny\"|y=\"yes\") =       0.222222 this mean if we get only synny ito acount we will conclude that y= no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39129c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1cd0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e908c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c88f70b8",
   "metadata": {},
   "source": [
    "<h2> References </h2>\n",
    "* <a href='https://towardsdatascience.com/implementing-naive-bayes-algorithm-from-scratch-python-c6880cfc9c41'>naive <br>\n",
    "* <a href='https://prwatech.in/blog/machine-learning/naive-bayes-classifier-in-machine-learning/'> Indian Naive Bayes </a> <br>\n",
    "* <a href='https://www.geeksforgeeks.org/naive-bayes-classifiers/'>Naive Bayes Classifiers </a>    \n",
    "    * <a href='https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c'>Naive Bayes Classifiers </a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072135c7",
   "metadata": {},
   "source": [
    "Now, you can obtain the values for each by looking at the dataset and substitute them into the equation. For all entries in the dataset, the denominator does not change, it remain static. Therefore, the denominator can be removed and a proportionality can be introduced.\n",
    "$$P(y| x_1,x_2,...,x_n ) \\propto p(Y)\\prod_{i=0}^{n}P(x_i|y)$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display, Markdown , Math \n",
    "\n",
    "sns.set()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string): display(Markdown(string))\n",
    "def latex(out): printmd(f'{out}')  \n",
    "def pr(string): printmd('***{}***'.format(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "   <font size=\"5\" face = \"Times New Roma\" color='#270336'>\n",
    "     Binary.........\n",
    "   </font> \n",
    " </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "  <p>\n",
    "    <a href =   \"https://github.com/daodavid\" > \n",
    "       <img src=\"https://cdn.thenewstack.io/media/2014/12/github-octocat.png\" align=\"left\" width=\"120\"  alt=\"daodavid\" >\n",
    "    </a>\n",
    "    <font face = \"Times New Roma\" size=\"4\"  color='#270336'>\n",
    "        author: daodeiv (David Stankov) \n",
    "    </font>\n",
    "</p>      \n",
    "</h2>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>\n",
    "  <font size=\"4\" face = \"Times New Roma\" color='#3f134f' > \n",
    "    <ul style=\"margin-left: 30px\">\n",
    "      <li><a href='#abstract'>Abstract </a> </li> <br>\n",
    "      <!--<li><a href='#int-1'>Introduction </a> </li><br> -->\n",
    "      <li><a href='#deff_softmax'>Softmaxt definition and  how it works?</a> </li><br>\n",
    "      <li><a href='#cross_entropy'>Cross-entropy Loss</a> </li><br>  \n",
    "      <li><a href='#optimization'>Optimization of softmax by Cross-entropy Loss and derivation of Gradient descent formula </a> </li><br>\n",
    "       <li><a href='#gradient'>Implementation of Gradient descent algorithm </a> </li><br> \n",
    "      <li><a href='#reg'>Regularization of gradient descent by learning rate and max iterations</a> </li><br>     \n",
    "       <li><a href='#conclusion'>Conclusion</a> </li><br>  \n",
    "        \n",
    "</ul>    \n",
    " </font>\n",
    "  </h6>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"1\" id=\"abstract\">... </font> \n",
    "<h2 face = \"Times New Roma\" color='#270336' >&nbsp; Abstract</h2>\n",
    "<br>\n",
    "<font face = \"Times New Roma\" size=\"4.5\"  color='#270336' style=\"margin-right: 45px; margin-left: 45px\" >\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; This paper contains a mathematical proof and implementation of Gradient Descent formula used as optimization alogithm in Cross-entropy Loss. We will use the Cross-entropy Loss or so-called Softmax Loss as an error function in the process of fitting estimator parameters. This notebook is focused on the mathematics behind softmax regression and its implementation rather than its application in multi-class classification. We will use the Iris dataset in order to perform the process of training data using the softmax implementation. In addition, we will see  how are different learning rates and max iterations impact on training algorithm </font> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"4\" color='#270336' face = \"Times New Roma\">\n",
    "  &nbsp;&nbsp; For our purpose, we gonna use the Iris dataset because it is comparatively simple and  very convenient  in the studying Machine Learning. \n",
    "</font>    \n",
    "<h6> \n",
    "    <font size=\"3\" color='#270336' face = \"Times New Roma\" >\n",
    "        &nbsp;&nbsp; Loading data : <br>\n",
    "</font>    \n",
    "</h6>  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=\"5\" id=\"deff_softmax\" color='#4a3e20'>\n",
    "    $$ (1) \\;\\; \\sigma_{softmax}({z^i})_{ij} =\\frac {e^{z_{ij}} }{ \\sum_i^k e^{z_{ik}} } $$ \n",
    "  </font>\n",
    "  <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"1\" id=\"intro\">... </font> \n",
    "<h2 face = \"Times New Roma\" color='#270336' >&nbsp; INtroduction</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"1\" id=\"intro\">... </font> \n",
    "<h2 face = \"Times New Roma\" color='#270336' >&nbsp; The origin of Sigmoid</h2>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\" color='#270336' face = \"Times New Roma\">\n",
    "  &nbsp;&nbsp; Odds ratio is  \n",
    "</font>   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
